{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Dataset\n",
    "\n",
    "\n",
    "\n",
    "  We will be using the CAMELS-GB dataset. This contains daily hydrometeorological data for around 670 catchments in Great Britain, as well as catchment attributes related to land use/land cover, geology, and climate. The data can be downloaded [here](https://catalogue.ceh.ac.uk/documents/8344e4f3-d2ea-44f5-8afa-86d2987543a9). However, I have already placed a copy of the data in the shared data directory for this course. The `SHARED_DATA_DIR` environment variable contains the full path to the shared data directory. In the following code we will create a new path variable so that we can easily navigate to the CAMELS-GB data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"/Users/smoulds/.vscode/extensions/ms-python.python-2025.20.1-darwin-arm64/python_files/python_server.py\", line 134, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"<string>\", line 6, in <module>\n",
       "TypeError: unsupported operand type(s) for /: 'str' and 'str'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "SHARED_DATADIR = Path(os.environ[\"SHARED_DATA_DIR\"])\n",
    "DATADIR = SHARED_DATADIR / '8344e4f3-d2ea-44f5-8afa-86d2987543a9' / 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Now Load the data for a catchment chosen at random. The timeseries data are stored as csv files, so we use Pandas to load them into a Pandas DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date  precipitation   pet  ...  shortwave_rad  longwave_rad  windspeed\n",
       "0 1970-10-01           9.93  1.02  ...          61.76        325.33       7.65\n",
       "1 1970-10-02           4.01  1.41  ...          93.56        294.20      10.03\n",
       "2 1970-10-03           7.27  1.17  ...          61.95        321.14       5.41\n",
       "3 1970-10-04           3.77  0.06  ...          42.83        341.28       7.27\n",
       "4 1970-10-05           1.19  1.56  ...          92.13        299.08       7.90\n",
       "\n",
       "[5 rows x 11 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "id = '97002'\n",
    "data = pd.read_csv(os.path.join(DATADIR, 'timeseries', f'CAMELS_GB_hydromet_timeseries_{id}_19701001-20150930.csv'), parse_dates=[0])\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Look at the CAMELS-GB [manuscript](https://doi.org/10.5194/essd-12-2459-2020) and find out the units of each variable. Verify that `discharge_spec` is consistent with `discharge_vol` (HINT: you will need to find the drainage area of your chosen catchment so you can convert the volume to a depth. For now, you can find out this information by looking at the [NRFA website](https://nrfa.ceh.ac.uk/data/search). Later we will use the static catchment attributes provided with CAMELS-GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     discharge_spec  discharge_vol  discharge_vol_computed\n",
       "457            1.12           5.37                5.351111\n",
       "458            1.05           5.03                5.016667\n",
       "459            1.08           5.20                5.160000\n",
       "460            1.19           5.73                5.685556\n",
       "461            1.12           5.37                5.351111\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a question of unit conversion. I will convert discharge_spec (mm/d) to volumetric discharge (m3/s). To do this, we need to know the area of the catchment. From the NRFA website for station 97002 we can see that the catchment area is 412.8km2.\n",
    "data['discharge_vol_computed'] = data['discharge_spec']\n",
    "data['discharge_vol_computed'] /= 1000 # mm/d -> m/d [1000 mm in 1m]\n",
    "data['discharge_vol_computed'] *= 412.8 * 1000 * 1000 # m/d -> m3/d [1 km2 = 1000 * 1000 m2]\n",
    "data['discharge_vol_computed'] /= 86400 # m3/d -> m3/s [1 day = 86400 seconds]\n",
    "print(data[['discharge_spec', 'discharge_vol', 'discharge_vol_computed']].dropna().head()) # Check approximate equality (note they will not be exactly equal due to rounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Later on it will be useful to have the catchment ID in the dataframe, so we add it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'] = id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can also see that the `discharge_vol` column contains `NaN` values - these usually indicate missing data. There are various things we can do to handle (or impute) missing values, but for now let's just remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['discharge_vol'])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Recall the water balance equation from lecture 1:\n",
    "\n",
    "\n",
    "\n",
    "  $\\frac{dS}{dt} = P - E - Q$\n",
    "\n",
    "\n",
    "\n",
    "  where $\\frac{dS}{dt}$ is the change in storage over time, $P$ is precipitation, $E$ is evaporation and $Q$ is streamflow. Also recall that over long time periods we can assume the storage term tends towards zero. Now we can write:\n",
    "\n",
    "\n",
    "\n",
    "  $0 = P - E - Q$\n",
    "\n",
    "\n",
    "\n",
    "  and hence:\n",
    "\n",
    "\n",
    "\n",
    "  $E = P - Q.$\n",
    "\n",
    "\n",
    "\n",
    "  This is convenient because evaporation is hard to measure accurately. Let's use the equation above to estimate the catchment-averaged evaporation. We will work at annual timescales so that we can reasonably assume that the storage term is negligible. First we need to compute the annual precipitation and discharge. To do this we typically use the \"water year\" instead of the calendar year. This avoids the potential for large errors in the water balance because catchment storage can vary significantly during the wet season. In the UK the water year is taken as 1st October to 30th September. Fortunately Pandas has some magic that allows us to easily aggregate by water year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['water_year'] = data['date'].dt.to_period('Y-SEP')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `Y-SEP` is a period alias for \"annual frequency, anchored end of September\". Learn more about period aliases by consulting the [Pandas documentation](https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-period-aliases).\n",
    "\n",
    "Now we group our dataframe by the new `water_year` column, and compute the sum of precipitation and discharge. Before doing this we need to convert discharge_vol from m3/s (daily average discharge) to m3/day (daily total discharge):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['discharge_vol'] *= 60 * 60 * 24 # m3/s -> m3/day\n",
    "anndata = data.groupby(['id', 'water_year'])[['precipitation', 'pet', 'discharge_spec', 'discharge_vol']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Aggregating data is an extremely useful skill in hydrology. Think about how you might use Pandas to aggregate by month or by season.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  When making comparisons between catchments, it is common to transform all variables to a *depth* so that the effect of catchment area is reduced. This allows us to compare the hydrological behaviour of a large catchment (e.g. Tweed) with a much smaller catchment. Let's load the catchment attributes and find the area of our catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(DATADIR, f'CAMELS_GB_topographic_attributes.csv'))\n",
    "metadata['gauge_id'] = metadata['gauge_id'].astype(str)\n",
    "area = metadata[metadata['gauge_id'] == id]['area'].values[0]\n",
    "area *= 1e6 # km2 -> m2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Let's return to the question I posed above, about verifying that discharge_spec is consistent with discharge_vol. Let's transform our volumetric data to depth units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndata['discharge_spec_computed'] = anndata['discharge_vol'].copy() # m3/day\n",
    "anndata['discharge_spec_computed'] /= area # m3 -> m\n",
    "anndata['discharge_spec_computed'] *= 1000 # m -> mm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  If you look at the dataframe, you see that column `discharge_vol` is now the same as `discharge_spec`. In future, you can use `discharge_spec` directly, without the need for transformation. We now have everything we need to estimate evaporation using the water balance equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   discharge_spec  discharge_spec_computed      diff\n",
       "0          275.61               275.705385 -0.095385\n",
       "1          436.02               436.039838 -0.019838\n",
       "2          612.14               612.204285 -0.064285\n",
       "3          661.68               661.747539 -0.067539\n",
       "4          477.49               477.428373  0.061627\n",
       "0.05063917987050362\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anndata['diff'] = anndata['discharge_spec'] - anndata['discharge_spec_computed']\n",
    "print(anndata[['discharge_spec', 'discharge_spec_computed', 'diff']].head())\n",
    "print(anndata['diff'].abs().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndata['evaporation'] = anndata['precipitation'] - anndata['discharge_spec_computed']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Let's plot this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "anndata = anndata.set_index('water_year')\n",
    "anndata.plot(y=['precipitation', 'discharge_spec', 'evaporation'], figsize=(12, 6))\n",
    "\n",
    "plt.title(f'Water balance for catchment {id}')\n",
    "plt.xlabel('Water year end')\n",
    "plt.ylabel('Depth (mm)')\n",
    "plt.legend(['Precipitation', 'Discharge', 'Evaporation'])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "anndata = anndata.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Instead of estimating evaporation at the annual scale, we could also do this at the monthly or seasonal scale. Here is a helpful code snippet for adding the season to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      id season_year season  ...  season_index  plot_index  season_label\n",
       "0  97002        1972    DJF  ...             1        7889      1972-DJF\n",
       "2  97002        1972    MAM  ...             2        7890      1972-MAM\n",
       "1  97002        1972    JJA  ...             3        7891      1972-JJA\n",
       "6  97002        1973    SON  ...             0        7892      1973-SON\n",
       "3  97002        1973    DJF  ...             1        7893      1973-DJF\n",
       "\n",
       "[5 rows x 10 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def month_to_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'DJF'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'MAM'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'JJA'\n",
    "    else:\n",
    "        return 'SON'\n",
    "\n",
    "# Align year to start in September - this ensures that DJF (which spans two calendar years) is grouped correctly\n",
    "data['season_year'] = data['date'].dt.to_period('Y-AUG')\n",
    "data['season'] = data.date.dt.month.apply(month_to_season)\n",
    "seasondata = data.groupby(['id', 'season_year', 'season'])[['precipitation', 'pet', 'discharge_spec', 'discharge_vol']].sum().reset_index()\n",
    "\n",
    "# The plot order is not logical at the season scale, so we need to add a couple of extra columns\n",
    "season_order = {\n",
    "    'SON': 0,\n",
    "    'DJF': 1,\n",
    "    'MAM': 2,\n",
    "    'JJA': 3\n",
    "}\n",
    "seasondata['season_index'] = seasondata['season'].map(season_order)\n",
    "seasondata['plot_index'] = (\n",
    "    seasondata['season_year'].dt.year * 4 # multiply by 4 because there are four seasons\n",
    "    + seasondata['season_index']\n",
    ")\n",
    "seasondata = seasondata.sort_values('plot_index')\n",
    "seasondata['season_label'] = (\n",
    "    seasondata['season_year'].dt.year.astype(str)\n",
    "    + '-'\n",
    "    + seasondata['season']\n",
    ")\n",
    "print(seasondata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now you can compute seasonal evaporation in the same way as before. However, this time you will need to use the `plot_index` column for the x-axis. What do you notice about the seasonal evaporation? Are there any seasons where evaporation is negative? What might this imply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"/Users/smoulds/.vscode/extensions/ms-python.python-2025.20.1-darwin-arm64/python_files/python_server.py\", line 134, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"<string>\", line 1, in <module>\n",
       "NotImplementedError\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seasondata['evaporation'] = seasondata['precipitation'] - seasondata['discharge_spec']\n",
    "seasondata = seasondata.set_index('plot_index')\n",
    "seasondata.plot(y=['precipitation', 'discharge_spec', 'evaporation'], figsize=(12, 6))\n",
    "plt.title(f'Water balance for catchment {id}')\n",
    "plt.xlabel('Water year end')\n",
    "plt.ylabel('Depth (mm)')\n",
    "plt.legend(['Precipitation', 'Discharge', 'Evaporation'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative evaporation is impossible. It is indicative of an incorrect assumption that $\\frac{dS}{dt} = 0$ at the seasonal scale. Intuitively this makes sense - in the UK, we would expect the catchment to contain more water in its various stores (e.g. groundwater, lakes, reservoirs etc.) at the end of winter compared to the start, because winter is our wettest season. On the other hand, we would expect the catchment to contain less water at the end of summer. In fact the end of summer tends to be the annual minimum in terms of catchment water storage, which is why the start of the water year is taken as the 1 October. \n",
    "\n",
    "We can also express this mathematically. Since \n",
    "\n",
    "$E = P - Q - \\frac{dS}{dt}$ \n",
    "\n",
    "Under our (incorrect) assumption that $\\frac{dS}{dt} = 0$, when $E < 0$, $Q > P$. This suggests that streamflow is being sustained by water that fell in a previous season - i.e., water is being released from storage (either through natural processes or human intervention) to become streamflow. Note that while $E < 0$ is physically impossible, $\\frac{dS}{dt} < 0$ is possible - it means that the change in storage with respect to time is negative - i.e. the stores are emptying rather than filling up. Note also that because evaporation must be greater than or equal to zero, the situation $P < Q$ is not limited to occasions when $E < 0$ in our dataframe above. The reality is that water is constantly moving from the atmosphere, to various catchment water stores, to streamflow. The main point is that the relative magnitude of these processes varies in time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Land cover impacts\n",
    "\n",
    "\n",
    "\n",
    "  We will cover the drivers of evaporation in more detail later on the course. One question we may have is the role of different land cover types on the water balance. Let's investigate whether land use impacts evaporation by looking at some forested catchments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_lu = pd.read_csv(os.path.join(DATADIR, f'CAMELS_GB_landcover_attributes.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Have a look at the columns in `metadata_lu` and consult Coxon et al. (2020). Which columns represent forest? Create a new column called `forest_perc` that combines the two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   gauge_id  dwood_perc  ewood_perc  forest_perc\n",
       "0     10002        3.89        5.41         9.30\n",
       "1     10003        4.74        3.06         7.80\n",
       "2      1001        0.41       12.37        12.78\n",
       "3    101002        6.20        0.30         6.50\n",
       "4    101005        4.60        0.12         4.72\n",
       "count    671.000000\n",
       "mean      13.863949\n",
       "std       11.641904\n",
       "min        0.000000\n",
       "25%        6.340000\n",
       "50%       10.920000\n",
       "75%       17.065000\n",
       "max       92.780000\n",
       "Name: forest_perc, dtype: float64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_lu['forest_perc'] = metadata_lu[['ewood_perc', 'dwood_perc']].sum(axis=1)\n",
    "print(metadata_lu[['gauge_id', 'dwood_perc', 'ewood_perc', 'forest_perc']].head())\n",
    "print(metadata_lu['forest_perc'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  To compare the impact of vegetation on runoff generation, it would be useful to compute a summary measure for each catchment. One such measure, or signature, is the runoff ratio, defined as the proportion of precipitation that becomes runoff. We can calculate this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Runoff ratio for catchment 97002: 0.6345938008054475\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anndata_sum = anndata.groupby('id')[['precipitation', 'discharge_spec_computed']].sum()\n",
    "anndata_sum['runoff_ratio'] = anndata_sum['discharge_spec_computed'] / anndata_sum['precipitation']\n",
    "print(f\"Runoff ratio for catchment {id}: {anndata_sum['runoff_ratio'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What does the runoff ratio tell us about the catchment? Would you expect the number to be higher or lower for an arid catchment? What about a humid catchment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Optional exercise\n",
    "\n",
    "\n",
    "\n",
    " 1. Divide the catchments into three groups: Low forest (<10%), Medium forest (10-30%) and High forest (>30%).\n",
    "\n",
    " 2. Compute the runoff ratio for every catchment (HINT: write a loop to perform the steps outlined above).\n",
    "\n",
    " 3. Make a boxplot showing the distribution of runoff ratios for each group.\n",
    "\n",
    " 4. Can you see a clear pattern? Consider the following questions:\n",
    "\n",
    "    (i)   Is this is a fair comparison (HINT: look at the number of catchments in each group)?\n",
    "\n",
    "    (ii)  What other factors might be influencing the runoff ratio?\n",
    "\n",
    "    (iii) How could you improve this analysis? How might statistical or machine learning models help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's divide the catchments into three groups. We can do this by applying a function across rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forest_group\n",
       "medium    312\n",
       "low       309\n",
       "high       50\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def forest_group(x):\n",
    "    if x < 10:\n",
    "        return \"low\"\n",
    "    elif x < 30:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "metadata_lu[\"forest_group\"] = metadata_lu[\"forest_perc\"].apply(forest_group)\n",
    "print(metadata_lu['forest_group'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the runoff ratio for every catchment. To do this we need (i) a list of catchment IDs, (ii) a function to load the catchment data and (iii) a function to calculate the runoff ratio. Here is my attempt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   gauge_id  forest_perc forest_group  runoff_ratio\n",
       "0     10002         9.30          low      0.564977\n",
       "1     10003         7.80          low      0.414309\n",
       "2      1001        12.78       medium      0.278004\n",
       "3    101002         6.50          low      0.366922\n",
       "4    101005         4.72          low      0.257316\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_camels_data(id): \n",
    "    # Read CAMELS-GB data for a given catchment id\n",
    "    data = pd.read_csv(os.path.join(DATADIR, 'timeseries', f'CAMELS_GB_hydromet_timeseries_{id}_19701001-20150930.csv'), parse_dates=[0])\n",
    "    return data \n",
    "\n",
    "def compute_runoff_ratio(data):\n",
    "    # Compute runoff ratio for a given catchment dataframe\n",
    "    data_sum = data.groupby('id')[['precipitation', 'discharge_spec']].sum()\n",
    "    data_sum['runoff_ratio'] = data_sum['discharge_spec'] / data_sum['precipitation']\n",
    "    return data_sum\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get a list of catchment IDs \n",
    "ids = metadata_lu['gauge_id'].astype(int).tolist()\n",
    "rr_list = []\n",
    "for id in tqdm(ids): \n",
    "    data = read_camels_data(id)\n",
    "    data['id'] = id\n",
    "    rr = compute_runoff_ratio(data)\n",
    "    rr_list.append(rr)\n",
    "\n",
    "rr = pd.concat(rr_list)\n",
    "rr = rr.merge(metadata_lu, how='left', left_on='id', right_on='gauge_id')\n",
    "print(rr[['gauge_id', 'forest_perc', 'forest_group', 'runoff_ratio']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: enforce ordering\n",
    "order = ['low', 'medium', 'high']\n",
    "rr['forest_group'] = pd.Categorical(rr['forest_group'], categories=order, ordered=True)\n",
    "\n",
    "# There are a few errors in the runoff ratio calculation that lead to values > 1. These can be filtered out.\n",
    "rr = rr[rr['runoff_ratio'] <= 1.0]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "rr.boxplot(column='runoff_ratio', by='forest_group', grid=False)\n",
    "\n",
    "plt.title('Runoff ratio by forest cover group')\n",
    "plt.suptitle('')  # removes the automatic \"Boxplot grouped by ...\" title\n",
    "plt.xlabel('Forest cover group')\n",
    "plt.ylabel('Runoff ratio (Q/P)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that on average, catchments with high forest content tends to have a higher average runoff ratio. This is not what we would expect! Generally we would say that, all else being equal, heavily forested catchments would have higher evaporation and hence the runoff ratio would be lower (more evaporation = less discharge). This suggests that forest cover is acting as a proxy for some other control on runoff ratio. In Great Britain, forested catchments tend to be in upland areas in the north and west. Hence they are situated in areas that tend to be wetter on average. I would therefore suggest that climate might be a more dominant control on the runoff ratio than land cover. We will return to this topic in later weeks. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
